% Section 8: Conclusions

\section{Conclusions}

\subsection{Summary of Achieve Metrics for DC3a}

\subsection{Recommendations for DC3b and beyond}

The DC3a experience and results has already informed the plans for
DC3b at a detailed level.  For the results that have been presented in
this report, there are several high-level conclusions that are
particularly important for our future data challenge development:

\paragraph{Software Process.}  Early in DC3, the code tree underwent
significant refactoring and was additionally upgraded for 64-bit
support. These steps were important and necessary, but left developers
without the ability to test implementations inside the harness for a
significant fraction of DC3a which encouraged integration to commence
later in DC3a than was desirable.  In DC3b, we plan to apply several
strategies of continuous integration and automated testing to avoid
these problems in the future.  

\paragraph{Scaling.}  Tests on the Abe cluster showed that the
pipelines scaled reasonably well when applied to the entire focal
plane of a CFHT-LS exposure. The pipeline stage harness supporting the
science algorithms was designed to be computationally lightweight, and
analysis of runs on Abe show that comparatively little processing time
is spent by this infrastructure.  Nevertheless, there remains
important scaling tests that still need to be completed, including
scaling up the full focal plane of the LSST.  We consider it critical
to complete the execution and analysis of these runs using DC3a to be
completed prior to the Preliminary Design Review (PDR).  

\paragraph{Scientific Performance.}  Our analysis of results have
focused a few areas that can have important effects on the scientific
performance of the detection of alert-able objects.  Detection and
elimination of artificial cosmic rays was ``perfect'' in that all
artifacts were detected; however, this occurred in only the first of
the two places where detection is done.  Thus, further testing will be
needed to determine the efficacy of the second phase.  The success of
WCS determination varied quite a bit as a function of amplifier: 4\%
of the amps failed in the first 32 amplifiers and only 0.5\% in the
second.  More improvements will be needed to address the quality image
subtraction:  while most sources are subtracting well (when the WCS is
sufficiently successful),  the bright sources feature much larger
errors.  

Limitations of our input data make it difficult to test our overall
ability to detect variable or moving sources.  More work is needed in
improving the simulated data; in particular, it will be important
create simulated template data that can support image subtraction with
simulated raw data.  

\paragraph{Processing Performance.}  While we made important
improvements in the performance of certain algorithms (including image
subtraction), the overall time to process a visit still exceeded that
for DC2.  That is, our gains were ``lost'' by virtue of
including more of the processing that is part of alert production,
particularly the processing of the second visit exposure.  Analysis of
the processing times point to two tall poles that can be addressed.
Image subtraction represents 96\% of the time doing actual image
processing, and the remainder covers only one third of our allotted
budget; clearly substantial improvements in this algorithm are still
critically needed.  Goods gains could also be gotten by improving the
``add-and-detect'' algorithm.  

\paragraph{I/O Performance.}  I/O performance is also a clear
bottleneck for performance as we spent nearly three times our time
budget for image processing on I/O.  While our runs on Abe
supercomputer do show that the Lustre parallel filesystem is important
for improving that performance; however, we saw that naive use of a
parallel file system can be detrimental.  In future data challenges,
we need put more effort into strategies for efficient I/O.  Database
performance is also an issue, and further scaling tests are needed.  

It will be fortunate if advancing computing technology over the next
few years could eliminate a bit of performance deficit we are seeing
today.  Unfortunately, computing chip roadmaps are looking to
multi-core processing for keeping up with Moore's law.  This means, we
can only take advantage of that to the extent that we can make our
application more parallel.  We are currently parallelizing on our
smallest natural level--the amplifier, so parallelizing even farther
would not be trivial.  GPU-based processing is promising, and we plan
to start experimenting with this in DC3b. 





