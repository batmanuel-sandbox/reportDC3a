% section 4: Input Data

\section{Input Data}

For DC3, we used two sources for images to be input to the pipelines.
As in DC2, we used real images from the CFHT Legacy Survey
(CFHT-LS)\footnote{http://www.cfht.hawaii.edu/Science/CFHLS/} along
with their associated source catalogs.  The CFHT-LS Deep Survey images
come from the Canadian-France-Hawaii Telescope using the MegaCam
mosaicing camera. The camera features a focal plane of 36 CCDs, where
each CCD contains 2048 $\times$ 4612 pixels. The total field of view
for the camera is a full 1 degree $\times$ 1 degree square with a
resolution of 0.187 arcsecond per pixel.

The CFHT-LS dataset was chosen for its similarities to what will be
the character of LSST data.  That is, like LSST, the CFHT-LS survey
features repeated observations of the same fields of the sky with a
mosaic camera.  The fact that this is ``real science data'' provides
the benefit of being subject to real-world observational artifacts
that we will face with LSST.  For DC3a, we introduced simulated images
generated specifically for LSST, along with the catalog data generated
as part of the simulation process.  This dataset has the advantage of
not only exactly matching the observational parameters we plan for
LSST (e.g. images size and focal plane configuration) but also being
based on a known ``true sky'' that we can compare our processed
results to.

\subsection{CFHT-LS Deep Survey Data}

In DC2, calibrated images released by the CFHT-LS Deep Survey were used as 
input. As one of the goals of DC3 was the creation of an instrument signature 
removal (ISR) pipeline, we instead used raw images and the related 
calibration data: flats, darks, and fringes. These raw and calibration
images are in FITS format; metadata stored in their FITS file 
headers allowed for matching up between exposures and the calibration
data for that given camera run.

New source detection requires that each image be subtracted from a
template image representing the fixed objects in the field of view,
so that the difference image can be analyzed. In DC2 a series of 
templates were pre-calculated, one for each segment of the images to 
be processed. In DC3, the template image is extracted as needed
from a larger template image. For the CFHT-LS images, this larger
template image was a stacked image created by the survey using
the best 25\% of exposures of the field.



\subsubsection{Science Data Products}

The ``raw'' archival science data obtained from CFHT have gone through
a modicum of pre--processing by the CFHT {\tt ELIXIR}
pipeline\footnote{\url{http://cfht.hawaii.edu/Instruments/Imaging/MegaPrime/rawdata.html}}.
In particular, the two amplifier readouts were spliced back together
into 2112 by 4644 pixel images corresponding to a single CCD.  To
prepare the data for DC3a processing, we undid this operation to some
degree, while still maintaining consistency between the valid data
sections, overscan regions, and approximate Wcs information in the
image headers. 

For DC3a processing, we divided each of the 32 CCD images into 8 images
that are approximately the anticipated size of LSST amplifier images.
Synthesized amplifier images 0-3 come from CFHT image subsection {\tt
[0:1056, 0:4612]} of the input images, and amplifier images 4-7 from
{\tt [1056:2112, 0:4612]}; there is an additional overscan region from
$4612 \leq y \leq 4644$ that is ignored.  Each resulting amplifier
image is 1056 x 1153 pixels, with 32 pixels of overscan implemented as
``prescan'' (amplifiers 0-3) or ``postscan'' (amplifiers 4-7).  
When segmenting the images, special care was taken to properly migrate
header data describing important characteristics such as noise, gain,
and bias for each amplifier.  Each amplifier image was saved with a
file name that captured a visit ID (taken from the \texttt{OBSID} FITS
keyword), CCD ID, amplifier ID, and exposure ID (indicating whether it
is the first or second in the pair of visit exposures).  

The full focal plane of the CFHT data--namely, the number of amplifier
sub-images and constituent pixels--is substantially smaller than
the planned LSST focal plane.  In order to scale up our pipelines to
run on a full LSST focal plane all at once using this data, we need to
effectively replicate this data multiple times.  We note that we were
not able to complete this level of scaling in time for this report.  

\subsubsection{Calibration Data}

The CFHT calibration data includes FITS keywords that define the range
of dates for which it is valid.  In order to process CFHT science frames
we needed to associate a given filter and date with the proper
calibrations.  This mapping was captured in a policy file and used by
one of the stages of the IPSD pipeline to lookup and match a given
exposure to the appropriate calibration product.  

We note that CFHT-LS documentation explains that the flat images
provided by the survey contain systematic errors on large scales
resulting in variations from image center to corner of a few percent.
We have not attempted to correct for this effect in DC3a,  although it
is clear that the final LSST system will need to do so.

\subsection{LSST Simulated Images and Catalogs}

Three sets of simulated images were generated for the LSST data
management pipeline: ``Deep'' images comprise 96 CCD images of the
same field (with varying seeing, airmass and sky backgrounds) and were
designed for use in image stacks, ``Wide'' images comprise 163 CCDS
which sample 3 rafts from the center to the edge of the focal plane
over a range of airmasses and seeing conditions, ``Ideal'' images
comprise a simulation with no atmosphere, no optical distortions,
airmass of unity, 0.1 arcsec seeing and no sky background (this
defines an idealized view of the sky for use as a truth table).

The underlying stellar and galaxy catalogs are based on the
simulations of Juri\'c {\it et al.}~(2008) and Kitzbichler and White
(2007) respectively.  To reproduce the LSST sky coverage the 2x2 deg
galaxy catalogs from Kitzbichler and White (2007) are tiled across the
sky.  The SED of each galaxy is estimated using the Bruzual \& Charlot
(2003) stellar population models. Using the models of Debattista
\textit{et al.}~(2006) each galaxy in the Millennium Simulation is
assigned a morphological profile. The current implementation assigns
each galaxy a disk-to-total flux ratio, position angle in the sky,
inclination along the line-of-sight, bulge radius, and disk radius.

Stars are specified by SED, and positions. The SEDs for stars are
derived from Kurucz models (i.e.\ excluding dwarf and giant
stars). The model used to generate main sequence stars is based on
work done by Juric et. al. This includes user-specified amounts of
thick-disk, thin-disk, and halo stars. Each version of a catalog
contains metadata on metallicity, temperature, luminosity-type, and
surface gravity.

From these data, images with varying PSF (from 0.4 to 1.8 arcseconds),
airmass (from 1.0 to 2.0), sky background ( with low, new moon, and
high, full moon and 20 degrees from the Moon), and varying mirror and
optics specifications (including aberrations) were generated.  The
limiting magnitude of these catalogs was $r<26$ and the catalogs were
made available with the resulting images.

\subsubsection{Science Data Products}

Images were output in standard FITS format. Each 65MB FITS file
represents a single 4096x4096 CCD 15 second exposure with 0.2 arcsec
pixels and covers 13.6x13.6 arcminutes of the sky. Each FITS file
contains keywords required by the LSST data reduction pipelines
including date, data sections, saturation level, and world coordinate
system (WCS).  Amplifier based images were constructed by breaking up
each CCD into 16 amplifier images (512 $\times$ 2045 pixels), addition
of an overscan region of 5 pixels, and inclusion of read noise of 5
elections.  A software bias of 100 counts was added to all the pixels
to avoid negative counts.  All amplifier-level FITS images were cast
as 16-bit unsigned integer. The FITS keywords for these images include
the simulation run name (i.e. Wide, Deep, or Ideal), dates processed
at University of Washington and generated at Purdue, along with CCD
processing information (i.e. DATASEC, etc..)

The Image Simulation results predict non-linear distortions in the
coordinate system, at the sub-pixel level, across a CCD. To meet the
LSST science--goal astrometric requirements (15 milliarcsec) and to
account for these non-linear optical distortions, a TAN-SIP WCS
solution was implemented for these images. TAN-SIP provides a
polynomial relation between CCD positions and the position on the sky
(where the order of the polynomial is user-specified). The TAN-SIP
convention is supported by the publically available software package
WCSTools and by Saoimage DS9. 

\subsubsection{Calibration Data Products}

Calibration data products for the simulated images include flat field
images, dark frames, and bias frames. The flat field images were set
to a mean value of unity and the dark and bias frames had a mean value
of zero.

\subsection{Event Generation From Input Data}

As described in section \ref{sec:components}, pipeline processing is
triggered by an event indicating that new image data is
ready.  This event contains basic metadata about the images--the
direction of sky, the filter, etc.  In our reference design, this
event ultimately comes from the process responsible for pulling the
data from the camera, and the information resides new loaded in the
database.  In DC3a where our data is in the FITS headers of images
already cached on disk.  In lieu of a data transfer process, we have a
simple script which that for a sequence of FITS files extracts the
information from the headers and emits it as data events to trigger
the pipeline processing.

