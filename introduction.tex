% section 1: Introduction

\section{Introduction}

Data Challenge 3 (DC3) is the third in a series of prototypes of the
LSST Data Management System (DMS). Through these data challenges, we
seek to identify the most challenging technical problems to building a
DMS that meets the LSST science goals. We prototype specific solutions
to these challenges with the expectation that by the start of the
construction phase of the telescope, we will have a well-defined plan
for how to build a DMS that can perform at the level needed by first
light. Despite the prototyping nature of the data challenges, we are
not producing throwaway code; rather, we expect that the software we
produce in the data challenges will serve as the foundation for the
DMS that will be completed during the construction phase.  In Data
Challenge 2 (DC2; Axelrod {\it et al.} 2008), we focused on
demonstrating the use of astronomical algorithms for nightly
processing in an LSST processing framework.  The scope of DC3 is
significantly larger, including both a more capable implementation of
the Alert Production and a first prototype implementation of the Data
Release Production.

Because of the large scope of DC3, we have divided it into two phases,
DC3a and b.  DC3a includes only the Alert Production capabilities,
while DC3b adds the Data Release Production.  This report describes
the results of DC3a only. We enumerate our goals, summarize the
implementation, and report on what we've learned from it.

\subsection{Goals of DC3a}

The goals of DC3a were in part an outcome of the DC2 post-mortem
analysis.  The DC2 report (Axelrod {\it et al.} 2008) listed several
areas where improvement was needed, and these have largely been
incorporated into the DC3a goals, which are as follows:

\begin{itemize}
\item Application Framework improvements
\item Middleware improvements
\item Implement the Instrument Signature Removal (ISR) pipeline
\item Implement the Image Characterization Pipeline (ICP), in
  particular the determination of the WCS.
\item Implement an initial SDQA system
\item Improve the science quality of the difference images and
  resulting catalogs
\item Improve the execution speed to a level that gives confidence in
  scaling to the full LSST
\item Improve the capabilities of the software build system
\end{itemize}

\subsection{Metrics and Validation of DC3a}

For DC3a, we have instituted a more quantitative set of metrics to
evaluate the outcome than we used for DC2.  They are as follows:

\begin{itemize}
\item UML model completeness - more generally, SQA metrics
\item Visit latency
\item Fraction of input images that complete pipeline processing
  without software crashes or exceptions
\item Fraction of input images with a successful WCS determination
  (registration to template image better than 0.5 arcsec)
\item Fraction of successfully subtracted images (RMS noise over whole
  image $\leq$ 1.5*sky; RMS of residuals around bright isolated stars
  $\leq$ XX*peak unsubtracted value)
\end{itemize}

The achieved values of these metrics are presented in Section \ref{metrics}.
